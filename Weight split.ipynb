{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79459d8d",
   "metadata": {},
   "source": [
    "Step 1: Start with the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91d58173",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "x = torch.tensor([[\n",
    "    [1.0, 2.0, 3.0, 4.0, 5.0, 6.0], # the\n",
    "    [6.0, 5.0, 4.0, 3.0, 2.0, 1.0], # kid\n",
    "    [1.0, 1.0, 1.0, 1.0, 1.0, 1.0]  # smiles\n",
    "]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c90bd0cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 6])\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "batch_size, seq_len, d_model = x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98987300",
   "metadata": {},
   "source": [
    "Step 2: Decide d_out and num_heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a365cd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_out = 6 # Keeping dim same as input\n",
    "num_heads = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3b1dc0",
   "metadata": {},
   "source": [
    "Step 3: Initialise Wq, Wk, Wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71de0381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each weight matrix will have dim (d_model x d_model) i.e 6x6.\n",
    "torch.manual_seed(0)\n",
    "Wq = torch.randn(d_model, d_model)\n",
    "Wk = torch.randn(d_model, d_model)\n",
    "Wv = torch.randn(d_model, d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe85d3b8",
   "metadata": {},
   "source": [
    "Step 4: Calculate Q, K, V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0a1cbbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q:\n",
      " tensor([[[ -9.0244, -11.7287,  15.5360,  -1.4474,  -4.5326,   9.4674],\n",
      "         [ -8.0564, -13.2309,   8.2228,  -8.9680,   3.1995,   4.8321],\n",
      "         [ -2.4401,  -3.5657,   3.3941,  -1.4879,  -0.1904,   2.0428]]])\n",
      "K:\n",
      " tensor([[[  8.2602,  14.1116,  -5.0345, -16.4865,  -2.9948,   8.3139],\n",
      "         [ -6.1188,  -0.1587,  -5.0885, -14.3014,   4.9540,   5.6093],\n",
      "         [  0.3059,   1.9933,  -1.4461,  -4.3983,   0.2799,   1.9890]]])\n",
      "V:\n",
      " tensor([[[ 0.5076, -3.4353,  1.8576,  2.8041,  8.9427, 13.1841],\n",
      "         [-1.9113, -3.6934,  1.8502,  1.7622,  1.6981,  3.0978],\n",
      "         [-0.2005, -1.0184,  0.5297,  0.6523,  1.5201,  2.3260]]])\n"
     ]
    }
   ],
   "source": [
    "# result will be of size (1, 3, 6) since size of x is (1, 3, 6) and size of W is (6,6)\n",
    "Q = x @ Wq\n",
    "K = x @ Wk\n",
    "V = x @ Wv\n",
    "\n",
    "print(\"Q:\\n\", Q)\n",
    "print(\"K:\\n\", K)\n",
    "print(\"V:\\n\", V)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075326e0",
   "metadata": {},
   "source": [
    "Step 5: Unroll the last dimension of Q, K, V to include num_heads\n",
    "\n",
    "Q, K, V : 1 x 3 x 6 [3D] --> 1 x 3 x 2 x 3 [4D]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9bdfec71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q after unrolling:\n",
      " tensor([[[[ -9.0244, -11.7287,  15.5360],\n",
      "          [ -1.4474,  -4.5326,   9.4674]],\n",
      "\n",
      "         [[ -8.0564, -13.2309,   8.2228],\n",
      "          [ -8.9680,   3.1995,   4.8321]],\n",
      "\n",
      "         [[ -2.4401,  -3.5657,   3.3941],\n",
      "          [ -1.4879,  -0.1904,   2.0428]]]])\n",
      "K after unrolling:\n",
      " tensor([[[[  8.2602,  14.1116,  -5.0345],\n",
      "          [-16.4865,  -2.9948,   8.3139]],\n",
      "\n",
      "         [[ -6.1188,  -0.1587,  -5.0885],\n",
      "          [-14.3014,   4.9540,   5.6093]],\n",
      "\n",
      "         [[  0.3059,   1.9933,  -1.4461],\n",
      "          [ -4.3983,   0.2799,   1.9890]]]])\n",
      "V after unrolling:\n",
      " tensor([[[[ 0.5076, -3.4353,  1.8576],\n",
      "          [ 2.8041,  8.9427, 13.1841]],\n",
      "\n",
      "         [[-1.9113, -3.6934,  1.8502],\n",
      "          [ 1.7622,  1.6981,  3.0978]],\n",
      "\n",
      "         [[-0.2005, -1.0184,  0.5297],\n",
      "          [ 0.6523,  1.5201,  2.3260]]]])\n"
     ]
    }
   ],
   "source": [
    "head_dim = 3\n",
    "Q = Q.view(1, 3, num_heads, head_dim)\n",
    "K = K.view(1, 3, num_heads, head_dim)\n",
    "V = V.view(1, 3, num_heads, head_dim)\n",
    "\n",
    "print(\"Q after unrolling:\\n\", Q)\n",
    "print(\"K after unrolling:\\n\", K)\n",
    "print(\"V after unrolling:\\n\", V)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3eb605",
   "metadata": {},
   "source": [
    " ```\n",
    "Q after unrolling:\n",
    " tensor([[[[ -9.0244, -11.7287,  15.5360],  Head 1 for token 1\n",
    "          [ -1.4474,  -4.5326,   9.4674]],  Head 2 for token 1\n",
    "\n",
    "         [[ -8.0564, -13.2309,   8.2228],   Head 1 for token 2\n",
    "          [ -8.9680,   3.1995,   4.8321]],  Head 2 for token 2\n",
    "\n",
    "         [[ -2.4401,  -3.5657,   3.3941],   Head 1 for token 3\n",
    "          [ -1.4879,  -0.1904,   2.0428]]]])Head 2 for token 3\n",
    "```\n",
    "Here the grouping is according to number of tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3021490",
   "metadata": {},
   "source": [
    "Step 6: Group matrices by number of heads\n",
    "\n",
    "Q, K, V : 1x3x2x3 [batch, num_tokens, num_heads, head_dim]\n",
    "\n",
    "to\n",
    "\n",
    "Q, K, V : 1x2x3x3 [batch, num_heads, num_tokens, head_dim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dab4e7ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q after grouping by heads:\n",
      " tensor([[[[ -9.0244, -11.7287,  15.5360],\n",
      "          [ -8.0564, -13.2309,   8.2228],\n",
      "          [ -2.4401,  -3.5657,   3.3941]],\n",
      "\n",
      "         [[ -1.4474,  -4.5326,   9.4674],\n",
      "          [ -8.9680,   3.1995,   4.8321],\n",
      "          [ -1.4879,  -0.1904,   2.0428]]]])\n",
      "K after grouping by heads:\n",
      " tensor([[[[  8.2602,  14.1116,  -5.0345],\n",
      "          [ -6.1188,  -0.1587,  -5.0885],\n",
      "          [  0.3059,   1.9933,  -1.4461]],\n",
      "\n",
      "         [[-16.4865,  -2.9948,   8.3139],\n",
      "          [-14.3014,   4.9540,   5.6093],\n",
      "          [ -4.3983,   0.2799,   1.9890]]]])\n",
      "V after grouping by heads:\n",
      " tensor([[[[ 0.5076, -3.4353,  1.8576],\n",
      "          [-1.9113, -3.6934,  1.8502],\n",
      "          [-0.2005, -1.0184,  0.5297]],\n",
      "\n",
      "         [[ 2.8041,  8.9427, 13.1841],\n",
      "          [ 1.7622,  1.6981,  3.0978],\n",
      "          [ 0.6523,  1.5201,  2.3260]]]])\n"
     ]
    }
   ],
   "source": [
    "Q = Q.transpose(1, 2)\n",
    "K = K.transpose(1, 2)\n",
    "V = V.transpose(1, 2)\n",
    "\n",
    "print(\"Q after grouping by heads:\\n\", Q)\n",
    "print(\"K after grouping by heads:\\n\", K)\n",
    "print(\"V after grouping by heads:\\n\", V)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ad0b08",
   "metadata": {},
   "source": [
    "```\n",
    "Q after grouping by heads:\n",
    " tensor([[[[ -9.0244, -11.7287,  15.5360],  Head 1 Token 1\n",
    "          [ -8.0564, -13.2309,   8.2228],   Head 1 Token 2\n",
    "          [ -2.4401,  -3.5657,   3.3941]],  Head 1 Token 3\n",
    "\n",
    "         [[ -1.4474,  -4.5326,   9.4674],   Head 2 Token 1\n",
    "          [ -8.9680,   3.1995,   4.8321],   Head 2 Token 2\n",
    "          [ -1.4879,  -0.1904,   2.0428]]]])    Head 2 Token 3\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ee8913",
   "metadata": {},
   "source": [
    "Step 7: Prepare K transpose for attention scores calculation\n",
    "\n",
    "K: 1x2x3x3 [batch, num_heads, num_tokens, head_dim]\n",
    "\n",
    "K_T: 1x2x3x3 [batch, num_heads, head_dim, num_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d2e1a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K before transpose:\n",
      " tensor([[[[  8.2602,  14.1116,  -5.0345],\n",
      "          [ -6.1188,  -0.1587,  -5.0885],\n",
      "          [  0.3059,   1.9933,  -1.4461]],\n",
      "\n",
      "         [[-16.4865,  -2.9948,   8.3139],\n",
      "          [-14.3014,   4.9540,   5.6093],\n",
      "          [ -4.3983,   0.2799,   1.9890]]]])\n",
      "K after transpose:\n",
      " tensor([[[[  8.2602,  -6.1188,   0.3059],\n",
      "          [ 14.1116,  -0.1587,   1.9933],\n",
      "          [ -5.0345,  -5.0885,  -1.4461]],\n",
      "\n",
      "         [[-16.4865, -14.3014,  -4.3983],\n",
      "          [ -2.9948,   4.9540,   0.2799],\n",
      "          [  8.3139,   5.6093,   1.9890]]]])\n"
     ]
    }
   ],
   "source": [
    "K_T = K.transpose(2, 3)\n",
    "\n",
    "print(\"K before transpose:\\n\", K)\n",
    "print(\"K after transpose:\\n\", K_T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8b9a9e",
   "metadata": {},
   "source": [
    "Step 8: Find attention scores\n",
    "\n",
    "Q*K_T : [batch, num_heads, num_tokens, num_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56d73d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention scores shape:\n",
      " torch.Size([1, 2, 3, 3])\n",
      "Attention scores:\n",
      " tensor([[[[-318.2692,  -21.9748,  -48.6063],\n",
      "          [-294.6534,    9.5538,  -40.7285],\n",
      "          [ -87.5604,   -1.7744,  -12.7621]],\n",
      "\n",
      "         [[ 116.1476,   51.3506,   23.9283],\n",
      "          [ 178.4425,  171.2106,   49.9505],\n",
      "          [  42.0843,   31.7945,   10.5541]]]])\n"
     ]
    }
   ],
   "source": [
    "attention_scores = Q @ K_T\n",
    "print(\"Attention scores shape:\\n\", attention_scores.shape)\n",
    "print(\"Attention scores:\\n\", attention_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3608399f",
   "metadata": {},
   "source": [
    "```\n",
    "Attention scores:   the          kid      smiles\n",
    " tensor([[      [[-318.2692,  -21.9748,  -48.6063],     the\n",
    "        Head 1  [-294.6534,    9.5538,  -40.7285],      kid\n",
    "                [ -87.5604,   -1.7744,  -12.7621]],     smiles\n",
    "\n",
    "                [[ 116.1476,   51.3506,   23.9283],     the\n",
    "        Head 2  [ 178.4425,  171.2106,   49.9505],      kid\n",
    "                [  42.0843,   31.7945,   10.5541]]]])   smiles\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9ebc3e",
   "metadata": {},
   "source": [
    "Step 9: Apply causal mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9441d872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Causal mask\n",
      " tensor([[False,  True,  True],\n",
      "        [False, False,  True],\n",
      "        [False, False, False]])\n",
      "Attention scores after masking:\n",
      " tensor([[[[-318.2692,      -inf,      -inf],\n",
      "          [-294.6534,    9.5538,      -inf],\n",
      "          [ -87.5604,   -1.7744,  -12.7621]],\n",
      "\n",
      "         [[ 116.1476,      -inf,      -inf],\n",
      "          [ 178.4425,  171.2106,      -inf],\n",
      "          [  42.0843,   31.7945,   10.5541]]]])\n"
     ]
    }
   ],
   "source": [
    "mask = torch.triu(torch.ones(seq_len, seq_len), diagonal=1).bool()\n",
    "print(\"Causal mask\\n\", mask)\n",
    "attention_scores.masked_fill_(mask, -torch.inf)\n",
    "print(\"Attention scores after masking:\\n\", attention_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c32abb",
   "metadata": {},
   "source": [
    "Step 10: Calculate attention weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1345fe28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights shape:\n",
      " torch.Size([1, 2, 3, 3])\n",
      "Attention weights:\n",
      " tensor([[[[    1.000,     0.000,     0.000],\n",
      "          [    0.000,     1.000,     0.000],\n",
      "          [    0.000,     0.998,     0.002]],\n",
      "\n",
      "         [[    1.000,     0.000,     0.000],\n",
      "          [    0.985,     0.015,     0.000],\n",
      "          [    0.997,     0.003,     0.000]]]])\n"
     ]
    }
   ],
   "source": [
    "torch.set_printoptions(precision=3, sci_mode=False) # Turn off scientific notation\n",
    "attention_weights = torch.softmax(attention_scores / head_dim**0.5, dim=-1)\n",
    "print(\"Attention weights shape:\\n\", attention_weights.shape)\n",
    "print(\"Attention weights:\\n\", attention_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf326e2",
   "metadata": {},
   "source": [
    "Step 11: Apply dropouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e49fd051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights after dropout:\n",
      " tensor([[[[    1.111,     0.000,     0.000],\n",
      "          [    0.000,     1.111,     0.000],\n",
      "          [    0.000,     1.109,     0.002]],\n",
      "\n",
      "         [[    1.111,     0.000,     0.000],\n",
      "          [    1.094,     0.017,     0.000],\n",
      "          [    1.108,     0.003,     0.000]]]])\n"
     ]
    }
   ],
   "source": [
    "dropout = torch.nn.Dropout(0.1)\n",
    "attention_weights = dropout(attention_weights)\n",
    "print(\"Attention weights after dropout:\\n\", attention_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f50abc",
   "metadata": {},
   "source": [
    "Step 12: Calculate context vectors\n",
    "\n",
    "attention weight: [batch_size, num_heads, num_tokens, num_tokens] -> 1x2x3x3\n",
    "\n",
    "value matrix : [batch_size, num_heads, num_tokens, head_dim] -> 1x2x3x3\n",
    "\n",
    "context vector  = attention weights * value matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2bf01595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context vectors shape:\n",
      " torch.Size([1, 2, 3, 3])\n",
      "Context vectors:\n",
      " tensor([[[[ 0.564, -3.817,  2.064],\n",
      "          [-2.124, -4.104,  2.056],\n",
      "          [-2.120, -4.099,  2.053]],\n",
      "\n",
      "         [[ 3.116,  9.936, 14.649],\n",
      "          [ 3.098,  9.814, 14.479],\n",
      "          [ 3.113,  9.915, 14.620]]]])\n"
     ]
    }
   ],
   "source": [
    "context_vectors = attention_weights @ V\n",
    "print(\"Context vectors shape:\\n\", context_vectors.shape)\n",
    "print(\"Context vectors:\\n\", context_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae542f6",
   "metadata": {},
   "source": [
    "```\n",
    "Context vectors:\n",
    " tensor([[      [[ 0.564, -3.817,  2.064],       token 1\n",
    "        Head 1  [-2.124, -4.104,  2.056],        token 2\n",
    "                [-2.120, -4.099,  2.053]],       token 3\n",
    "\n",
    "                [[ 3.116,  9.936, 14.649],       token 1\n",
    "       Head 2   [ 3.098,  9.814, 14.479],        token 2\n",
    "                [ 3.113,  9.915, 14.620]]]])     token 3\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed9dafa",
   "metadata": {},
   "source": [
    "Step 13: Reformat and concatenate\n",
    "\n",
    "context vectors : attention weights * values matrix --> [batch, num_heads, num_tokens, head_dim]\n",
    "\n",
    "Our starting vector input was [1, 3, 6]\n",
    "\n",
    "First swap num_heads with num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22a63276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context vectors shape after swapping dimension 1 and 2:\n",
      " torch.Size([1, 3, 2, 3])\n",
      "Context vectors:\n",
      " tensor([[[[ 0.564, -3.817,  2.064],\n",
      "          [ 3.116,  9.936, 14.649]],\n",
      "\n",
      "         [[-2.124, -4.104,  2.056],\n",
      "          [ 3.098,  9.814, 14.479]],\n",
      "\n",
      "         [[-2.120, -4.099,  2.053],\n",
      "          [ 3.113,  9.915, 14.620]]]])\n"
     ]
    }
   ],
   "source": [
    "context_vectors = context_vectors.transpose(1, 2)\n",
    "print(\"Context vectors shape after swapping dimension 1 and 2:\\n\", context_vectors.shape)\n",
    "print(\"Context vectors:\\n\", context_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d683f08",
   "metadata": {},
   "source": [
    "```\n",
    "Context vectors:\n",
    " tensor([[[[ 0.564, -3.817,  2.064],    Token 1 Head 1\n",
    "          [ 3.116,  9.936, 14.649]],    Token 1 Head 2\n",
    "\n",
    "         [[-2.124, -4.104,  2.056],     Token 2 Head 1\n",
    "          [ 3.098,  9.814, 14.479]],    Token 2 Head 2\n",
    "\n",
    "         [[-2.120, -4.099,  2.053],     Token 3 Head 1\n",
    "          [ 3.113,  9.915, 14.620]]]])  Token 3 Head 2\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026b58a1",
   "metadata": {},
   "source": [
    "Then merge last two dimensions to get the shape [batch, num_tokens, d_out]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aea5a0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context vectors shape after concatenating heads:\n",
      " torch.Size([1, 3, 6])\n",
      "Context vectors:\n",
      " tensor([[[ 0.564, -3.817,  2.064,  3.116,  9.936, 14.649],\n",
      "         [-2.124, -4.104,  2.056,  3.098,  9.814, 14.479],\n",
      "         [-2.120, -4.099,  2.053,  3.113,  9.915, 14.620]]])\n"
     ]
    }
   ],
   "source": [
    "context_vectors = context_vectors.reshape(batch_size, seq_len, num_heads * head_dim)\n",
    "print(\"Context vectors shape after concatenating heads:\\n\", context_vectors.shape)\n",
    "print(\"Context vectors:\\n\", context_vectors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
