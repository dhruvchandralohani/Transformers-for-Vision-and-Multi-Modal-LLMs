{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "048096fe",
   "metadata": {},
   "source": [
    "Input sequence: Dream big and work for it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09401e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "inputs = torch.tensor(\n",
    "    [\n",
    "        [0.72, 0.45, 0.31],# 'Dream' (x^1)\n",
    "        [0.75, 0.20, 0.55],# 'big'   (x^2)\n",
    "        [0.30, 0.80, 0.40],# 'and'   (x^3)\n",
    "        [0.85, 0.35, 0.60],# 'work'  (x^4)\n",
    "        [0.55, 0.15, 0.75],# 'for'   (x^5)\n",
    "        [0.25, 0.20, 0.85],# 'it'    (x^6)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Corresponding words\n",
    "words = ['Dream', 'big', 'and', 'work', 'for', 'it']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4e81b3",
   "metadata": {},
   "source": [
    "We want to generate the context vector for second token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "767c3b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input embedding for 'big': tensor([0.7500, 0.2000, 0.5500])\n",
      "Input dimension: 3\n",
      "Output dimension: 2\n"
     ]
    }
   ],
   "source": [
    "x_2 = inputs[1]  # Embedding for 'big'\n",
    "print(f\"Input embedding for 'big': {x_2}\")\n",
    "d_in = inputs.shape[1]  # Input dimension\n",
    "print(f\"Input dimension: {d_in}\")\n",
    "d_out = 2  # Output dimension\n",
    "print(f\"Output dimension: {d_out}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc4dd26",
   "metadata": {},
   "source": [
    "Randomly initialising the Wk, Wq, Wv matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a844a21e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W_query:\n",
      "Parameter containing:\n",
      "tensor([[-0.1115,  0.1204],\n",
      "        [-0.3696, -0.2404],\n",
      "        [-1.1969,  0.2093]])\n",
      "\n",
      "W_key:\n",
      "Parameter containing:\n",
      "tensor([[-0.9724, -0.7550],\n",
      "        [ 0.3239, -0.1085],\n",
      "        [ 0.2103, -0.3908]])\n",
      "\n",
      "W_value:\n",
      "Parameter containing:\n",
      "tensor([[ 0.2350,  0.6653],\n",
      "        [ 0.3528,  0.9728],\n",
      "        [-0.0386, -0.8861]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)  # For reproducibility\n",
    "W_query = torch.nn.Parameter(torch.randn(d_in, d_out), requires_grad=False)\n",
    "print(f\"W_query:\\n{W_query}\\n\")\n",
    "W_key = torch.nn.Parameter(torch.randn(d_in, d_out), requires_grad=False)\n",
    "print(f\"W_key:\\n{W_key}\\n\")\n",
    "W_value = torch.nn.Parameter(torch.randn(d_in, d_out), requires_grad=False)\n",
    "print(f\"W_value:\\n{W_value}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca3a3b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query vector for 'big': tensor([-0.8158,  0.1573])\n",
      "\n",
      "Key vector for 'big': tensor([-0.5488, -0.8030])\n",
      "\n",
      "Value vector for 'big': tensor([0.2256, 0.2062])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query_2 = x_2 @ W_query\n",
    "print(f\"Query vector for 'big': {query_2}\\n\")\n",
    "key_2 = x_2 @ W_key\n",
    "print(f\"Key vector for 'big': {key_2}\\n\")\n",
    "value_2 = x_2 @ W_value\n",
    "print(f\"Value vector for 'big': {value_2}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d255d9ee",
   "metadata": {},
   "source": [
    "Calculating Q, K & V using inputs(X), Wq, Wk & Wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c07a7afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys:\n",
      "tensor([[-4.8914e-01, -7.1363e-01],\n",
      "        [-5.4880e-01, -8.0295e-01],\n",
      "        [ 5.1548e-02, -4.6967e-01],\n",
      "        [-5.8694e-01, -9.1428e-01],\n",
      "        [-3.2846e-01, -7.2469e-01],\n",
      "        [ 4.7331e-04, -5.4268e-01]])\n",
      "\n",
      "Values:\n",
      "tensor([[ 0.3160,  0.6421],\n",
      "        [ 0.2256,  0.2062],\n",
      "        [ 0.3373,  0.6234],\n",
      "        [ 0.3000,  0.3743],\n",
      "        [ 0.1532, -0.1528],\n",
      "        [ 0.0965, -0.3923]])\n",
      "\n",
      "Queries:\n",
      "tensor([[-0.6176,  0.0433],\n",
      "        [-0.8158,  0.1573],\n",
      "        [-0.8079, -0.0725],\n",
      "        [-0.9423,  0.1437],\n",
      "        [-1.0144,  0.1871],\n",
      "        [-1.1192,  0.1599]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "keys = inputs @ W_key\n",
    "print(f\"Keys:\\n{keys}\\n\")\n",
    "values = inputs @ W_value\n",
    "print(f\"Values:\\n{values}\\n\")\n",
    "queries = inputs @ W_query\n",
    "print(f\"Queries:\\n{queries}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4645088",
   "metadata": {},
   "source": [
    "Keys corresponding to the second token and the attention of second token to itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49e5fbdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key vector for second token ('big'): tensor([-0.5488, -0.8030])\n",
      "\n",
      "Attention score between 'big' and 'big': 0.3214397430419922\n",
      "\n"
     ]
    }
   ],
   "source": [
    "keys_2 = keys[1]\n",
    "print(f\"Key vector for second token ('big'): {keys_2}\\n\")\n",
    "attention_score_22 = query_2.dot(keys_2)\n",
    "print(f\"Attention score between 'big' and 'big': {attention_score_22}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1eeb397",
   "metadata": {},
   "source": [
    "All attenstion scores for query number 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03a0c1cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All attention scores for query number 2:\n",
      "tensor([ 0.2868,  0.3214, -0.1159,  0.3350,  0.1540, -0.0857])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "attention_scores_2 = queries[1] @ keys.T\n",
    "print(f\"All attention scores for query number 2:\\n{attention_scores_2}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371b4b92",
   "metadata": {},
   "source": [
    "Attention scores (not weights) matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd60ef4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention scores (not weights) matrix:\n",
      "tensor([[ 0.2712,  0.3042, -0.0522,  0.3229,  0.1715, -0.0238],\n",
      "        [ 0.2868,  0.3214, -0.1159,  0.3350,  0.1540, -0.0857],\n",
      "        [ 0.4469,  0.5016, -0.0076,  0.5405,  0.3179,  0.0390],\n",
      "        [ 0.3583,  0.4017, -0.1161,  0.4217,  0.2053, -0.0784],\n",
      "        [ 0.3627,  0.4065, -0.1402,  0.4244,  0.1976, -0.1020],\n",
      "        [ 0.4333,  0.4858, -0.1328,  0.5107,  0.2517, -0.0873]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "attention_scores = queries @ keys.T # omega matrix\n",
    "print(f\"Attention scores (not weights) matrix:\\n{attention_scores}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ab3a00",
   "metadata": {},
   "source": [
    "Scale by 1/sqrt(d) and then take softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cdddebda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All attention scores for query number 2:\n",
      "tensor([ 0.2868,  0.3214, -0.1159,  0.3350,  0.1540, -0.0857])\n",
      "\n",
      "All attention weights for query number 2:\n",
      "tensor([0.1821, 0.1867, 0.1370, 0.1885, 0.1658, 0.1400])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "d_k = keys.shape[-1]\n",
    "attention_weigths_2 = torch.nn.functional.softmax(attention_scores_2 / torch.sqrt(torch.tensor(d_k)), dim=-1)\n",
    "print(f\"All attention scores for query number 2:\\n{attention_scores_2}\\n\")\n",
    "print(f\"All attention weights for query number 2:\\n{attention_weigths_2}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6842ecf6",
   "metadata": {},
   "source": [
    "NOTE 1: Softmax peaks when numbers are scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83bc2012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Softmax of tensor([ 0.1000, -0.2000,  0.3000, -0.2000,  0.5000]) without scaling is tensor([0.1925, 0.1426, 0.2351, 0.1426, 0.2872])\n",
      "Softmax of tensor([ 0.1000, -0.2000,  0.3000, -0.2000,  0.5000]) with scaling is tensor([0.0326, 0.0030, 0.1615, 0.0030, 0.8000])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.tensor([0.1, -0.2, 0.3, -0.2, 0.5])\n",
    "softmax = torch.nn.functional.softmax(tensor, dim=-1)\n",
    "print(f\"Softmax of {tensor} without scaling is {softmax}\")\n",
    "scaled_tensor = tensor * 8\n",
    "scaled_softmax = torch.nn.functional.softmax(scaled_tensor, dim=-1)\n",
    "print(f\"Softmax of {tensor} with scaling is {scaled_softmax}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072697eb",
   "metadata": {},
   "source": [
    "NOTE 2: Scaling has to be such that the varince of QK.T is close to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68d57d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d_k: 8, Variance before scaling: 8.1428, Variance after scaling: 1.0179\n",
      "d_k: 16, Variance before scaling: 15.9418, Variance after scaling: 0.9964\n",
      "d_k: 32, Variance before scaling: 32.1296, Variance after scaling: 1.0040\n",
      "d_k: 64, Variance before scaling: 63.9599, Variance after scaling: 0.9994\n",
      "d_k: 128, Variance before scaling: 128.0868, Variance after scaling: 1.0007\n",
      "d_k: 256, Variance before scaling: 256.2036, Variance after scaling: 1.0008\n"
     ]
    }
   ],
   "source": [
    "# Function to compute variance before and after scaling\n",
    "def compute_variance_scaling(d_k, num_samples=10000):\n",
    "    q = torch.randn(num_samples, d_k)\n",
    "    k = torch.randn(num_samples, d_k)\n",
    "    scores = q @ k.T\n",
    "    var_before = torch.var(scores).item()\n",
    "    scaled_scores = scores / torch.sqrt(torch.tensor(d_k, dtype=torch.float32))\n",
    "    var_after = torch.var(scaled_scores).item()\n",
    "    return var_before, var_after\n",
    "\n",
    "d_k_values = [8, 16, 32, 64, 128, 256]\n",
    "for d_k in d_k_values:\n",
    "    var_before, var_after = compute_variance_scaling(d_k)\n",
    "    print(f\"d_k: {d_k}, Variance before scaling: {var_before:.4f}, Variance after scaling: {var_after:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c395f3c6",
   "metadata": {},
   "source": [
    "Context vector corresponding to second input token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d810c656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context vector corresponding to second input token:\n",
      "tensor([0.2413, 0.2311])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "context_vector_2 = attention_weigths_2 @ values\n",
    "print(f\"Context vector corresponding to second input token:\\n{context_vector_2}\\n\")\n",
    "# The context vector for the second token 'big' is computed by taking the weighted sum of the value vectors using the attention weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57c936ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "So, the input vector tensor([0.7500, 0.2000, 0.5500]) for the token 'big' is transformed to the context vector tensor([0.2413, 0.2311]) using self-attention mechanism.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"So, the input vector {inputs[1]} for the token '{words[1]}' is transformed to the context vector {context_vector_2} using self-attention mechanism.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f119ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights matrix:\n",
      "tensor([[0.1678, 0.1681, 0.1644, 0.1683, 0.1667, 0.1647],\n",
      "        [0.1681, 0.1685, 0.1639, 0.1686, 0.1667, 0.1642],\n",
      "        [0.1681, 0.1687, 0.1634, 0.1691, 0.1668, 0.1639],\n",
      "        [0.1683, 0.1688, 0.1634, 0.1690, 0.1667, 0.1638],\n",
      "        [0.1684, 0.1689, 0.1632, 0.1691, 0.1667, 0.1636],\n",
      "        [0.1686, 0.1692, 0.1628, 0.1694, 0.1667, 0.1632]])\n",
      "\n",
      "Context vectors for all input tokens:\n",
      "tensor([[0.2383, 0.2178],\n",
      "        [0.2384, 0.2181],\n",
      "        [0.2384, 0.2181],\n",
      "        [0.2384, 0.2183],\n",
      "        [0.2384, 0.2184],\n",
      "        [0.2385, 0.2185]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Attention weights for all queries\n",
    "attention_weights = torch.nn.functional.softmax(attention_scores / torch.sqrt(torch.tensor(d_k)), dim=-1)\n",
    "print(f\"Attention weights matrix:\\n{attention_weights}\\n\")\n",
    "# Context vectors for all input tokens\n",
    "context_vectors = attention_weights @ values\n",
    "print(f\"Context vectors for all input tokens:\\n{context_vectors}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab453ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "# Python class for generating context vectors using self-attention\n",
    "class selfAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, qkv_bias = False):\n",
    "        super().__init__()\n",
    "        self.W_q = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_k = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_v = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        keys = self.W_k(X)\n",
    "        queries = self.W_q(X)\n",
    "        values = self.W_v(X)\n",
    "\n",
    "        attention_scores = torch.nn.functional.softmax(queries @ keys.T / torch.sqrt(torch.tensor(keys.shape[-1])), dim=-1)\n",
    "        context_vectors = attention_scores @ values\n",
    "        return context_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a451a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context vectors from selfAttention class:\n",
      "tensor([[-0.5282, -0.0051],\n",
      "        [-0.5288, -0.0036],\n",
      "        [-0.5276, -0.0066],\n",
      "        [-0.5289, -0.0040],\n",
      "        [-0.5289, -0.0032],\n",
      "        [-0.5287, -0.0033]], grad_fn=<MmBackward0>)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)  # For reproducibility\n",
    "SA = selfAttention(d_in=3, d_out=2)\n",
    "context_vectors = SA(inputs)\n",
    "print(f\"Context vectors from selfAttention class:\\n{context_vectors}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
